{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1217b523",
   "metadata": {},
   "source": [
    "### Term Frequency - Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "378fc305",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dd4576",
   "metadata": {},
   "source": [
    "#### Create Data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f62956c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Text' : ['This pasta is tasty',\n",
    "                            'This pasta is not tasty'],\n",
    "                   'Output' : [1,0]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fe500136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This pasta is tasty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This pasta is not tasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Text  Output\n",
       "0      This pasta is tasty       1\n",
       "1  This pasta is not tasty       0"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95b5a86",
   "metadata": {},
   "source": [
    "#### In Output variable 1 means positive sentence and 0 means negative sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f704a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(ngram_range=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f884c698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761bdcd1",
   "metadata": {},
   "source": [
    "#### Here tfidf behave like uni gram because we intentionally give range ngram_range = (1,1) (on each unique word(vocab) of document it create seperate feature) but it has one additional facility is it gives tfidf score so we can understand which word is significant. That not done by uni gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde2c39f",
   "metadata": {},
   "source": [
    "#### Fit and transform data to tfidf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5128d67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "features= tfidf.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e5ac6e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4e91f8",
   "metadata": {},
   "source": [
    "#### Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d981779d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 4, 'pasta': 2, 'is': 0, 'tasty': 3, 'not': 1}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a56bc8",
   "metadata": {},
   "source": [
    "#### Here we provide ngram_range = (1,1) so it create 5 vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d0c0a",
   "metadata": {},
   "source": [
    "#### Metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4eb5358e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.        , 0.5       , 0.5       , 0.5       ],\n",
       "       [0.4090901 , 0.57496187, 0.4090901 , 0.4090901 , 0.4090901 ]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308993bc",
   "metadata": {},
   "source": [
    "#### Here we noticed in first document we have 4 words are significant and in 2nd document 1 word is signficant (0.57496187) . actually this is product of TF * IDF so which has highest TFIDF score that is signficant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcd878c",
   "metadata": {},
   "source": [
    "## TFIDF  on  uni and Bi gram (pairs of 2 consecutive words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "65e74ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_1 = TfidfVectorizer(ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8b7721f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer(ngram_range=(1, 2))</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer(ngram_range=(1, 2))</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer(ngram_range=(1, 2))"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14aa958a",
   "metadata": {},
   "source": [
    "#### Here we give (1,2) means its make vocab on single unique word and it make vocab on pair of words as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cbed6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_1 = tfidf_1.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6432124a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x10 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8151566e",
   "metadata": {},
   "source": [
    "#### Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5a0e2118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'pasta': 5, 'is': 0, 'tasty': 7, 'this pasta': 9, 'pasta is': 6, 'is tasty': 2, 'not': 3, 'is not': 1, 'not tasty': 4}\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_1.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29294381",
   "metadata": {},
   "source": [
    "#### Here it creates 10 vocabs . 5 by uni and 5 by bi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32363cef",
   "metadata": {},
   "source": [
    "#### Metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e23807fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35409974, 0.        , 0.49767483, 0.        , 0.        ,\n",
       "        0.35409974, 0.35409974, 0.35409974, 0.35409974, 0.35409974],\n",
       "       [0.2895694 , 0.40697968, 0.        , 0.40697968, 0.40697968,\n",
       "        0.2895694 , 0.2895694 , 0.2895694 , 0.2895694 , 0.2895694 ]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_1.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ca29a9",
   "metadata": {},
   "source": [
    "#### We get to know 0.49767483 is signficant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b9193",
   "metadata": {},
   "source": [
    "### TFIDF on Bi gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43f6c021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(ngram_range=(2, 2))\n",
      "****************************************************************************************************\n",
      "Vocabulary by TFIDF(Bi gram) :------>\n",
      "{'this pasta': 4, 'pasta is': 3, 'is tasty': 1, 'is not': 0, 'not tasty': 2}\n",
      "****************************************************************************************************\n",
      "[[0.         0.70490949 0.         0.50154891 0.50154891]\n",
      " [0.57615236 0.         0.57615236 0.40993715 0.40993715]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_2 = TfidfVectorizer(ngram_range = (2,2))\n",
    "\n",
    "\n",
    "print(tfidf_2)\n",
    "\n",
    "\n",
    "##### Here we give (2,2) means its make vocab on pair of words only.\n",
    "\n",
    "\n",
    "features_2 = tfidf_2.fit_transform(df['Text'])\n",
    "\n",
    "\n",
    "#print(features_2)\n",
    "\n",
    "\n",
    "##### Vocabs\n",
    "print('*****' * 20)\n",
    "print('Vocabulary by TFIDF(Bi gram) :------>')\n",
    "print(tfidf_2.vocabulary_)\n",
    "print('*****' * 20)\n",
    "\n",
    "\n",
    "# #### Here it creates 5 vocabs .\n",
    "\n",
    "##### Metrics to array\n",
    "\n",
    "print(features_2.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87dd878",
   "metadata": {},
   "source": [
    "#### In 1 st documennt we get high TFIDF score is 0.70490949 then it is signficant in 1st document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2041ef8d",
   "metadata": {},
   "source": [
    "### TFIDF on uni , Bi ,Tri gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "46c513cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(ngram_range=(1, 3))\n",
      "****************************************************************************************************\n",
      "Vocabulary by TFIDF(1,3) :------>\n",
      "{'this': 11, 'pasta': 6, 'is': 0, 'tasty': 10, 'this pasta': 12, 'pasta is': 7, 'is tasty': 3, 'this pasta is': 13, 'pasta is tasty': 9, 'not': 4, 'is not': 1, 'not tasty': 5, 'pasta is not': 8, 'is not tasty': 2}\n",
      "****************************************************************************************************\n",
      "[[0.30218978 0.         0.         0.42471719 0.         0.\n",
      "  0.30218978 0.30218978 0.         0.42471719 0.30218978 0.30218978\n",
      "  0.30218978 0.30218978]\n",
      " [0.24342027 0.3421187  0.3421187  0.         0.3421187  0.3421187\n",
      "  0.24342027 0.24342027 0.3421187  0.         0.24342027 0.24342027\n",
      "  0.24342027 0.24342027]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_3 = TfidfVectorizer(ngram_range = (1,3))\n",
    "\n",
    "\n",
    "print(tfidf_3)\n",
    "\n",
    "\n",
    "##### Here we give (3,3) means its make vocab single unique word and pair of word and 3 cons word.\n",
    "\n",
    "\n",
    "features_3 = tfidf_3.fit_transform(df['Text'])\n",
    "\n",
    "\n",
    "#print(features_3)\n",
    "\n",
    "\n",
    "##### Vocabs\n",
    "print('*****' * 20)\n",
    "print('Vocabulary by TFIDF(1,3) :------>')\n",
    "print(tfidf_3.vocabulary_)\n",
    "print('*****' * 20)\n",
    "\n",
    "\n",
    "# #### Here it creates 14 vocabs . 5 by uni gram and 5 by bi gram and 4 by tri gram\n",
    "\n",
    "##### Metrics to array\n",
    "\n",
    "print(features_3.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6d7095",
   "metadata": {},
   "source": [
    "#### In 1st documennt , 0.42471719 is highest TFIDF score so it is significant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e54b4c2",
   "metadata": {},
   "source": [
    "### TFIDF on Tri gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0e136d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(ngram_range=(3, 3))\n",
      "****************************************************************************************************\n",
      "Vocabulary by TFIDF(3,3) :------>\n",
      "{'this pasta is': 3, 'pasta is tasty': 2, 'pasta is not': 1, 'is not tasty': 0}\n",
      "****************************************************************************************************\n",
      "[[0.         0.         0.81480247 0.57973867]\n",
      " [0.6316672  0.6316672  0.         0.44943642]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_4 = TfidfVectorizer(ngram_range = (3,3))\n",
    "\n",
    "\n",
    "print(tfidf_4)\n",
    "\n",
    "\n",
    "##### Here we give (3,3) means its make vocab on 3 cons word.\n",
    "\n",
    "\n",
    "features_4 = tfidf_4.fit_transform(df['Text'])\n",
    "\n",
    "\n",
    "#print(features_4)\n",
    "\n",
    "\n",
    "##### Vocabs\n",
    "print('*****' * 20)\n",
    "print('Vocabulary by TFIDF(3,3) :------>')\n",
    "print(tfidf_4.vocabulary_)\n",
    "print('*****' * 20)\n",
    "\n",
    "\n",
    "# #### Here it creates 4 vocabs . 4 by tri gram\n",
    "\n",
    "##### Metrics to array\n",
    "\n",
    "print(features_4.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b3b366",
   "metadata": {},
   "source": [
    "#### In 1st document 0.81480247 and in 2nd document0.6316672 is signficant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eece8c9",
   "metadata": {},
   "source": [
    "### TFIDF on uni , bi , tri and tetra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "39c9c78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(ngram_range=(1, 4))\n",
      "****************************************************************************************************\n",
      "Vocabulary by TFIDF(1,4) :------>\n",
      "{'this': 12, 'pasta': 6, 'is': 0, 'tasty': 11, 'this pasta': 13, 'pasta is': 7, 'is tasty': 3, 'this pasta is': 14, 'pasta is tasty': 10, 'this pasta is tasty': 16, 'not': 4, 'is not': 1, 'not tasty': 5, 'pasta is not': 8, 'is not tasty': 2, 'this pasta is not': 15, 'pasta is not tasty': 9}\n",
      "Length of vocab : \n",
      "17\n",
      "****************************************************************************************************\n",
      "[[0.2781429  0.         0.         0.39092014 0.         0.\n",
      "  0.2781429  0.2781429  0.         0.         0.39092014 0.2781429\n",
      "  0.2781429  0.2781429  0.2781429  0.         0.39092014]\n",
      " [0.21912062 0.30796639 0.30796639 0.         0.30796639 0.30796639\n",
      "  0.21912062 0.21912062 0.30796639 0.30796639 0.         0.21912062\n",
      "  0.21912062 0.21912062 0.21912062 0.30796639 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_5 = TfidfVectorizer(ngram_range = (1,4))\n",
    "\n",
    "\n",
    "print(tfidf_5)\n",
    "\n",
    "\n",
    "#### Here we give (1,4) means its make vocab on uni gram (unique single word)  , bi (pair of word)\n",
    "### tri gram (3 cons word) and tetra gram( 4 cons word)\n",
    "\n",
    "\n",
    "features_5 = tfidf_5.fit_transform(df['Text'])\n",
    "\n",
    "\n",
    "#print(features_5)\n",
    "\n",
    "\n",
    "##### Vocabs\n",
    "print('*****' * 20)\n",
    "print('Vocabulary by TFIDF(1,4) :------>')\n",
    "print(tfidf_5.vocabulary_)\n",
    "print('Length of vocab : ')\n",
    "print(len(tfidf_5.vocabulary_))\n",
    "print('*****' * 20)\n",
    "\n",
    "\n",
    "# #### Here it creates 17 vocabs . 5  by uni , 5 by bi and 4 by tri gram and 3 by tetra\n",
    "\n",
    "##### Metrics to array\n",
    "\n",
    "print(features_5.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b3edfd",
   "metadata": {},
   "source": [
    "### TFIDF on tetra gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa7a9394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfVectorizer(ngram_range=(4, 4))\n",
      "****************************************************************************************************\n",
      "Vocabulary by TFIDF(4,4) :------>\n",
      "{'this pasta is tasty': 2, 'this pasta is not': 1, 'pasta is not tasty': 0}\n",
      "****************************************************************************************************\n",
      "[[0.         0.         1.        ]\n",
      " [0.70710678 0.70710678 0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_5 = TfidfVectorizer(ngram_range = (4,4))\n",
    "\n",
    "\n",
    "print(tfidf_5)\n",
    "\n",
    "\n",
    "##### Here we give (4,4) means its make vocab on 4 cons word.\n",
    "\n",
    "\n",
    "features_5 = tfidf_5.fit_transform(df['Text'])\n",
    "\n",
    "\n",
    "#print(features_5)\n",
    "\n",
    "\n",
    "##### Vocabs\n",
    "print('*****' * 20)\n",
    "print('Vocabulary by TFIDF(4,4) :------>')\n",
    "print(tfidf_5.vocabulary_)\n",
    "print('*****' * 20)\n",
    "\n",
    "\n",
    "##### Here it creates 3 vocabs . 3 by tri gram\n",
    "\n",
    "##### Metrics to array\n",
    "\n",
    "print(features_5.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25c0ca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
