{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a032f09",
   "metadata": {},
   "source": [
    "## Natural Language Tool Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2cc752",
   "metadata": {},
   "source": [
    "#### NLTK is primary library of python which is used for to processing and analysing the text data (Human language)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adee0fd",
   "metadata": {},
   "source": [
    "#### NLTK is provided some tools and resources to perform various NLP tasks like tokenization(split text into words) , stemming (reduce words in base form like running into run) and pos(parts of speech) tagging (identify grammaticial roles of the word  (noun , verb)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd098c",
   "metadata": {},
   "source": [
    "#### NLTK makes easier for programs to work with text data in python . to avoid build everything from scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a638656c",
   "metadata": {},
   "source": [
    "#### In simple words, NLTK is like a toolbox for text-related tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5995a215",
   "metadata": {},
   "source": [
    "#### It includes everything you need to:\n",
    "\n",
    "#### Split text into words and sentences. (Tokenization)\n",
    "#### Find the meaning of words (synonyms, antonyms). (sementic analysis)\n",
    "#### Identify the grammatical structure of sentences.(syntetic analysis)\n",
    "#### Classify text (e.g., identifying whether a review is positive or negative or neutral). (sentimental analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d120a306",
   "metadata": {},
   "source": [
    "### Features of NLTK: (We can perform this task by NLTK)\n",
    "\n",
    "#### 1.Tokenization : Split the text into words or sentences\n",
    "#### 2.Stemming : Reduce word into base / root word but it not worry about result is valid or not .it is faster but most of times word is not valid\n",
    "#### for eg :  achieve  ----> base word is achiev ,\n",
    "####               achieving -----> base word is achiev (by stemming)\n",
    "#### 3.Lemmatization : Reduce the word into meaningful base / root word basis on its cotext.means it gives valid root word . It is slower than stemming but result is valid\n",
    "#### for eg : achieve ------> base word is achieve\n",
    "####              achieving --------> base word is achieve\n",
    "#### 4.POS tagging : Identifying the grammatical roles of  words  eg : like 'I' is pronoun , 'am' is verb\n",
    "#### 5.text classification : classify the into categories  like spam detection\n",
    "#### 6.Named Entity Recognition (NER) : Recognize name of people , places , dates\n",
    "#### 7.WordNet : It is lexical database it helps to find relationship between the words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401be76",
   "metadata": {},
   "source": [
    "### Case study"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba10f193",
   "metadata": {},
   "source": [
    "##### We will do a case study where we perform tokenization and parts of speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270eb3d8",
   "metadata": {},
   "source": [
    "##### tokenize means we first split the sentence into words and parts of speech tag means tag or identify gramatical roles of that word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c7fdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6ac1802",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = 'I am running very fast'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb136e3a",
   "metadata": {},
   "source": [
    "#### Word tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01a13c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "effa144c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'am', 'running', 'very', 'fast']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e6b4b",
   "metadata": {},
   "source": [
    "#### sentence get split into words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf417c2",
   "metadata": {},
   "source": [
    "#### pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa1f26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_ = pos_tag(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7fb72c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('am', 'VBP'), ('running', 'VBG'), ('very', 'RB'), ('fast', 'RB')]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2de340",
   "metadata": {},
   "source": [
    "#### identify gramatical role of each word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cfa34d9",
   "metadata": {},
   "source": [
    "#### PRP : pronoun\n",
    "#### VBP : verb   [vb : verb and p : present tense]\n",
    "#### VBG : verb   [vb : verb and g : gerund] or present principle )\n",
    "#### RB : Adverb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e24ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = 'I love programming with Python'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29d21f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_1 = word_tokenize(sentence_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6367a229",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I', 'love', 'programming', 'with', 'Python']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e455cf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_1 = pos_tag(tokens_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "37621c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('I', 'PRP'), ('love', 'VBP'), ('programming', 'VBG'), ('with', 'IN'), ('Python', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c93d3",
   "metadata": {},
   "source": [
    "#### IN : preposition\n",
    "#### NNP : Proper Noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7db7858a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_2 = \"\"\" At eight o'clock on Thursday morning\n",
    "... Arthur didn't feel very good.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "68ee67bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_2 = word_tokenize(sentence_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d28e6f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At', 'eight', \"o'clock\", 'on', 'Thursday', 'morning', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n"
     ]
    }
   ],
   "source": [
    "print(tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "14312b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_tag_2 = pos_tag(tokens_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0657b555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('At', 'IN'), ('eight', 'CD'), (\"o'clock\", 'NN'), ('on', 'IN'), ('Thursday', 'NNP'), ('morning', 'NN'), ('Arthur', 'NNP'), ('did', 'VBD'), (\"n't\", 'RB'), ('feel', 'VB'), ('very', 'RB'), ('good', 'JJ'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(pos_tag_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6592e8",
   "metadata": {},
   "source": [
    "#### CD: cardinal Number (it represents number or specific quantity)\n",
    "#### NN : Noun\n",
    "#### JJ : adjective"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
