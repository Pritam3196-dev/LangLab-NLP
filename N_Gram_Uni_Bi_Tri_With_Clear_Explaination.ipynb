{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d50eb8cc",
   "metadata": {},
   "source": [
    "## N Grams : Feature Extraction method in NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3daded1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb57fac",
   "metadata": {},
   "source": [
    "#### Create data manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "944482b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Text' : ['This Pasta is tasty' , 'This pasta is not tasty'] , 'Output': [1,0]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce205a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This Pasta is tasty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This pasta is not tasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Text  Output\n",
       "0      This Pasta is tasty       1\n",
       "1  This pasta is not tasty       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9534e28",
   "metadata": {},
   "source": [
    "##### 1 means its positive sentence and 0 means its negative sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174ba7db",
   "metadata": {},
   "source": [
    "### Uni Gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb987aa",
   "metadata": {},
   "source": [
    "#### Uni Grams (ngram_range = 1, 1) means its bag of words means extract feature on the single word only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c47279fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv1 = CountVectorizer(ngram_range = (1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6e185a",
   "metadata": {},
   "source": [
    "#### Fit the data with countvectorizer(bow / uni grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2fa751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_gram = cv1.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be00d0d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 9 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d1256",
   "metadata": {},
   "source": [
    "#### Vocabulary in uni gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9852c009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 4, 'pasta': 2, 'is': 0, 'tasty': 3, 'not': 1}\n"
     ]
    }
   ],
   "source": [
    "print(cv1.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd21aaf0",
   "metadata": {},
   "source": [
    "#### We get five vocabs from n gram in one corpus (2 documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8416bd",
   "metadata": {},
   "source": [
    "#### metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80865267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_gram.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6d6463",
   "metadata": {},
   "source": [
    "### Uni Gram + Bi gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64204e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2 = CountVectorizer(ngram_range = (1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7bd2f6e",
   "metadata": {},
   "source": [
    "#### Here we create features/ vocabs on uni gram (on single word) and Bi gram(on pair of word i.e. 2 consecutive words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0127f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_bi_gram = cv2.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d06927f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x10 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_bi_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f0d1de",
   "metadata": {},
   "source": [
    "#### Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8156c420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 8, 'pasta': 5, 'is': 0, 'tasty': 7, 'this pasta': 9, 'pasta is': 6, 'is tasty': 2, 'not': 3, 'is not': 1, 'not tasty': 4}\n"
     ]
    }
   ],
   "source": [
    "print(cv2.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935a910",
   "metadata": {},
   "source": [
    "#### Here it create 10 vocabs.First on uni gram (on single word) and then Bi gram ( on pair of words)\n",
    "#### 5 vocabs by uni and another 5 vocabs by Bi gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e188e45",
   "metadata": {},
   "source": [
    "#### metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed4eba1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 1, 1, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_bi_gram.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388bad4c",
   "metadata": {},
   "source": [
    "## Bi gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aec78f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv3 = CountVectorizer(ngram_range = (2 ,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633ea2bf",
   "metadata": {},
   "source": [
    "##### Here it will create features or vocab only on pair of words (2 consecutive words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d1ad451",
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_gram = cv3.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f6df995",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 7 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b2b7d9",
   "metadata": {},
   "source": [
    "#### Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "092318e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this pasta': 4, 'pasta is': 3, 'is tasty': 1, 'is not': 0, 'not tasty': 2}\n"
     ]
    }
   ],
   "source": [
    "print(cv3.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ffc074",
   "metadata": {},
   "source": [
    "##### Here it built 5 features / vocabs only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07e8ce4",
   "metadata": {},
   "source": [
    "###### metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "474133a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 1, 1],\n",
       "       [1, 0, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi_gram.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fe7964",
   "metadata": {},
   "source": [
    "### Uni gram + Bi gram + Tri Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8a94090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv4 = CountVectorizer(ngram_range = (1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bae4adb",
   "metadata": {},
   "source": [
    "#### Here it create features or vocabs on single word and 2 cons word and 3 cons word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "488aad0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_bi_tri_gram = cv4.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ff63bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x14 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 21 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_bi_tri_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce9b00e",
   "metadata": {},
   "source": [
    "#### Vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b08a1415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this': 11, 'pasta': 6, 'is': 0, 'tasty': 10, 'this pasta': 12, 'pasta is': 7, 'is tasty': 3, 'this pasta is': 13, 'pasta is tasty': 9, 'not': 4, 'is not': 1, 'not tasty': 5, 'pasta is not': 8, 'is not tasty': 2}\n"
     ]
    }
   ],
   "source": [
    "print(cv4.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdd4796",
   "metadata": {},
   "source": [
    "##### Here it create 14 vocabs . 5 by uni and 5 by bi and 4 by tri gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce84edc7",
   "metadata": {},
   "source": [
    "#### metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ab124b01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uni_bi_tri_gram.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d334e3",
   "metadata": {},
   "source": [
    "### Tri Gram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b337cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv5 = CountVectorizer(ngram_range = (3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8150f006",
   "metadata": {},
   "source": [
    "#### Here it craete vocabs or feature on 3 cons words only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "33fbe027",
   "metadata": {},
   "outputs": [],
   "source": [
    "tri_gram = cv5.fit_transform(df['Text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d5376157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x4 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 5 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_gram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a9c47",
   "metadata": {},
   "source": [
    "#### metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0f34d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'this pasta is': 3, 'pasta is tasty': 2, 'pasta is not': 1, 'is not tasty': 0}\n"
     ]
    }
   ],
   "source": [
    "print(cv5.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf84263",
   "metadata": {},
   "source": [
    "#### It create only 4 vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877110ca",
   "metadata": {},
   "source": [
    "#### metrics to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a55b85fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 1],\n",
       "       [1, 1, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tri_gram.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7203f6",
   "metadata": {},
   "source": [
    "##### If remove stop word then also its meaning is not change or loss of meaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd3e65",
   "metadata": {},
   "source": [
    "#### But N grams having some Limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24a2d5e",
   "metadata": {},
   "source": [
    "#### 1.Sparsity when large data\n",
    "#### 2.It not able to tell which word is significant \n",
    "#### 3.oov (out of vocabulary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
